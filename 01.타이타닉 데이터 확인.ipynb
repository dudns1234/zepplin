{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"spark-dataframe\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "filepath = \"file:////home/ubuntu/working/spark-examples/data/titanic_train.csv\"\n",
        "\n",
        "titanic_sdf = spark.read.csv(filepath, inferSchema=True, header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "titanic_sdf.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "z.show(titanic_sdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "titanic_sdf.createOrReplaceTempView(\"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "query = \"\"\"\n",
        "    SELECT * FROM titanic\n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### DataLake -> DataWarehouse\n",
        "- survived, pclass, sex, age, Fare\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT\n",
        "        t.Survived, t.Sex, t.Pclass, t.Fare, t.Age\n",
        "    FROM titanic t \n",
        "\"\"\"\n",
        "\n",
        "titanic_wh = spark.sql(query)\n",
        "z.show(titanic_wh)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "titanic_wh.createOrReplaceTempView(\"titanic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DataWarehouse -> DataMart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## Fare 요금 이상치 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "# Q1, Q3 범위 정의\n",
        "q1 = titanic_wh.approxQuantile(\"Fare\", [0.25], 0.05)[0]\n",
        "q3 = titanic_wh.approxQuantile(\"Fare\", [0.75], 0.05)[0]\n",
        "\n",
        "# IQR 계산\n",
        "iqr = q3 - q1\n",
        "\n",
        "# 이상치 제거를 위한 상한선과 하한선 계산\n",
        "lower_bound = q1 - 1.5 * iqr\n",
        "upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "filtered_df = titanic_wh.filter((F.col(\"Fare\") >= lower_bound) & (F.col(\"Fare\") <= upper_bound))\n",
        "filtered_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "filtered_df.createOrReplaceTempView(\"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic\n",
        "\"\"\"\n",
        "\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 결측치 확인 후 제거"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "\n",
        "query = \"\"\"\n",
        "\n",
        "    SELECT *\n",
        "    FROM titanic\n",
        "    WHERE Age is not null\n",
        "      AND Survived is not null\n",
        "      AND Sex is not null\n",
        "      AND Pclass is not null\n",
        "\"\"\"\n",
        "titanic_result = spark.sql(query)\n",
        "z.show(titanic_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "%pyspark \n",
        "\n",
        "titanic_result.createOrReplaceTempView(\"titanic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "## 나이대 컬럼 추가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "def age_grade(age):\n",
        "    age_grade = int(age/10)*10\n",
        "    return age_grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "from pyspark.sql.types import LongType\n",
        "\n",
        "spark.udf.register('age_grade', age_grade, LongType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT\n",
        "        *, age_grade(Age) as Age_grade\n",
        "    FROM titanic\n",
        "\"\"\"\n",
        "titanic_result = spark.sql(query)\n",
        "z.show(titanic_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark \n",
        "# DataMart\n",
        "\n",
        "titanic_result.createOrReplaceTempView(\"titanic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA 계획\n",
        "\n",
        "- 생존한 남녀 수 비교 (count)\n",
        "- 남녀의 생존 비율\n",
        "- Pclass 별 Fare \n",
        "- Pclass 별 생존한 사람 수\n",
        "- 나이대 컬럼 생성해 나이대 별 생존한 사람 수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# 전체 남녀 수 비교 (count)\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic\n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# 생존한 남녀 수 비교\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic\n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# 남녀의 생존 비율\n",
        "# - Survived AVG : 생존은 1, 사망은 0 이므로 avg = 생존한 사람 수 / 전체 사람 수 = 1의 개수 / 전체 개수\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic\n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "\n",
        "# Pclass 별 Fare\n",
        "\n",
        "query = \"\"\"\n",
        "    SELECT t.Pclass, t.Fare\n",
        "    FROM titanic t\n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic \n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic \n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "# 나이대 생존 수\n",
        "query = \"\"\"\n",
        "    SELECT *\n",
        "    FROM titanic \n",
        "\"\"\"\n",
        "z.show(spark.sql(query))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": [
        "%pyspark\n",
        "spark.stop()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": [
        "%pyspark\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    },
    "name": "01 - 타이타닉 데이터 확인"
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
